{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Purchase Prediction - Exploratory Data Analysis\n",
    "\n",
    "## Business Context\n",
    "\n",
    "RetailTech Solutions is an international e-commerce platform seeking to optimize their marketing spend by predicting customer purchase likelihood based on browsing behavior. This analysis explores the customer session data to understand patterns and relationships that can inform our predictive modeling approach.\n",
    "\n",
    "## Dataset Overview\n",
    "\n",
    "The dataset contains 500 customer browsing sessions with 7 features capturing browsing behavior and demographic information. Our goal is to predict whether a customer will make a purchase (binary classification) based on their session characteristics.\n",
    "\n",
    "### Feature Description\n",
    "\n",
    "| Feature | Type | Description | Expected Range |\n",
    "|---------|------|-------------|----------------|\n",
    "| `customer_id` | Integer | Unique identifier | 1-500 (no missing) |\n",
    "| `time_spent` | Float | Minutes on website | 0+ minutes |\n",
    "| `pages_viewed` | Integer | Pages viewed in session | 0+ pages |\n",
    "| `basket_value` | Float | Basket monetary value | 0+ dollars |\n",
    "| `device_type` | Categorical | Device used | Mobile/Desktop/Tablet |\n",
    "| `customer_type` | Categorical | Customer status | New/Returning |\n",
    "| `purchase` | Binary | Target variable | 0=No, 1=Yes |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Load the raw data\n",
    "data_path = Path('../data/raw/raw_customer_data.csv')\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"Dataset shape: {df.shape[0]} rows Ã— {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality Assessment\n",
    "\n",
    "First, let's examine the data types, missing values, and basic statistics to understand data quality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine data types and missing values\n",
    "print(\"=== DATA TYPES ===\")\n",
    "print(df.dtypes)\n",
    "print(\"\\n=== MISSING VALUES ===\")\n",
    "missing_summary = df.isnull().sum()\n",
    "missing_percentage = (df.isnull().sum() / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_summary,\n",
    "    'Missing Percentage': missing_percentage\n",
    "})\n",
    "print(missing_df[missing_df['Missing Count'] > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Data Quality Findings:\n",
    "\n",
    "- **Dataset Size**: 500 customer sessions\n",
    "- **Missing Values**: Several features have missing data:\n",
    "  - `time_spent`: 13.0% missing (65 values)\n",
    "  - `pages_viewed`: 8.4% missing (42 values)\n",
    "  - `basket_value`: 16.6% missing (83 values)\n",
    "  - `device_type`: 3.8% missing (19 values)\n",
    "  - `customer_type`: 5.4% missing (27 values)\n",
    "- **Target Variable**: `purchase` has no missing values\n",
    "- **Customer ID**: Complete, can be used as index\n",
    "\n",
    "The missing values will need to be handled during preprocessing according to business rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Statistics\n",
    "\n",
    "Let's examine the statistical properties of our numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics for numerical features\n",
    "numerical_cols = ['time_spent', 'pages_viewed', 'basket_value']\n",
    "print(\"=== DESCRIPTIVE STATISTICS (Numerical Features) ===\")\n",
    "desc_stats = df[numerical_cols].describe()\n",
    "print(desc_stats.round(2))\n",
    "\n",
    "print(\"\\n=== TARGET DISTRIBUTION ===\")\n",
    "target_dist = df['purchase'].value_counts()\n",
    "target_pct = df['purchase'].value_counts(normalize=True) * 100\n",
    "target_summary = pd.DataFrame({\n",
    "    'Count': target_dist,\n",
    "    'Percentage': target_pct.round(2)\n",
    "})\n",
    "print(target_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Statistical Insights:\n",
    "\n",
    "**Numerical Features:**\n",
    "- **Time Spent**: Mean = 34.33 minutes, Std = 15.43 minutes, Range = 6.95-59.58 minutes\n",
    "- **Pages Viewed**: Mean = 9.78 pages, Std = 5.52 pages, Range = 1-19 pages\n",
    "- **Basket Value**: Mean = $49.63, Std = $27.57, Range = $0-$130.53\n",
    "\n",
    "**Target Variable:**\n",
    "- **Class Imbalance**: 81.4% purchases (407) vs 18.6% no-purchases (93)\n",
    "- **Imbalance Ratio**: ~4.4:1 (purchase:no-purchase)\n",
    "- **Business Implication**: This imbalance will need to be addressed in modeling\n",
    "\n",
    "The dataset shows a strong purchase bias, which is expected for e-commerce data but requires careful handling during model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Feature Analysis\n",
    "\n",
    "Let's examine the distribution of categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical feature distributions\n",
    "categorical_cols = ['device_type', 'customer_type']\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "for i, col in enumerate(categorical_cols):\n",
    "    # Get value counts (excluding missing values for visualization)\n",
    "    value_counts = df[col].value_counts()\n",
    "    \n",
    "    # Create bar plot\n",
    "    bars = axes[i].bar(range(len(value_counts)), value_counts.values, \n",
    "                       color=sns.color_palette(\"husl\", len(value_counts)))\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, value in zip(bars, value_counts.values):\n",
    "        axes[i].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5, \n",
    "                    f'{value}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    axes[i].set_title(f'Distribution of {col.replace(\"_\", \" \").title()}', fontsize=14, fontweight='bold')\n",
    "    axes[i].set_xticks(range(len(value_counts)))\n",
    "    axes[i].set_xticklabels(value_counts.index, rotation=45)\n",
    "    axes[i].set_ylabel('Count')\n",
    "    axes[i].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed statistics\n",
    "print(\"=== CATEGORICAL FEATURE DETAILS ===\")\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{col.replace('_', ' ').title()}:\")\n",
    "    counts = df[col].value_counts()\n",
    "    percentages = df[col].value_counts(normalize=True) * 100\n",
    "    summary = pd.DataFrame({'Count': counts, 'Percentage': percentages.round(2)})\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Feature Insights:\n",
    "\n",
    "**Device Type Distribution:**\n",
    "- **Mobile**: 45.8% (229 users) - Largest segment\n",
    "- **Desktop**: 34.0% (170 users)\n",
    "- **Tablet**: 16.4% (82 users)\n",
    "- **Missing**: 3.8% (19 users)\n",
    "\n",
    "**Customer Type Distribution:**\n",
    "- **Returning**: 58.2% (291 users) - Majority are repeat customers\n",
    "- **New**: 36.4% (182 users)\n",
    "- **Missing**: 5.4% (27 users)\n",
    "\n",
    "**Business Implications:**\n",
    "- Mobile dominates device usage (nearly half of sessions)\n",
    "- Returning customers represent the majority, suggesting good retention\n",
    "- Missing values in categorical features will be imputed as specified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Distributions by Target\n",
    "\n",
    "Let's examine how our features vary between purchasers and non-purchasers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature distributions by purchase outcome\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Numerical features\n",
    "numerical_cols = ['time_spent', 'pages_viewed', 'basket_value']\n",
    "\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    # Separate data by purchase outcome\n",
    "    purchase_data = df[df['purchase'] == 1][col].dropna()\n",
    "    no_purchase_data = df[df['purchase'] == 0][col].dropna()\n",
    "    \n",
    "    # Create histograms\n",
    "    axes[i].hist(purchase_data, alpha=0.7, label='Purchase', bins=20, density=True)\n",
    "    axes[i].hist(no_purchase_data, alpha=0.7, label='No Purchase', bins=20, density=True)\n",
    "    \n",
    "    axes[i].set_title(f'{col.replace(\"_\", \" \").title()} by Purchase Outcome', fontweight='bold')\n",
    "    axes[i].set_xlabel(col.replace('_', ' ').title())\n",
    "    axes[i].set_ylabel('Density')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(alpha=0.3)\n",
    "\n",
    "# Categorical features\n",
    "categorical_cols = ['device_type', 'customer_type']\n",
    "\n",
    "for i, col in enumerate(categorical_cols):\n",
    "    ax_idx = i + 3\n",
    "    \n",
    "    # Create cross-tabulation\n",
    "    cross_tab = pd.crosstab(df[col].fillna('Missing'), df['purchase'], normalize='index') * 100\n",
    "    \n",
    "    # Plot\n",
    "    cross_tab.plot(kind='bar', ax=axes[ax_idx], width=0.8)\n",
    "    axes[ax_idx].set_title(f'{col.replace(\"_\", \" \").title()} vs Purchase Rate', fontweight='bold')\n",
    "    axes[ax_idx].set_xlabel(col.replace('_', ' ').title())\n",
    "    axes[ax_idx].set_ylabel('Purchase Rate (%)')\n",
    "    axes[ax_idx].legend(['No Purchase', 'Purchase'])\n",
    "    axes[ax_idx].tick_params(axis='x', rotation=45)\n",
    "    axes[ax_idx].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical comparison\n",
    "print(\"=== STATISTICAL COMPARISON BY PURCHASE OUTCOME ===\")\n",
    "for col in numerical_cols:\n",
    "    purchase_mean = df[df['purchase'] == 1][col].mean()\n",
    "    no_purchase_mean = df[df['purchase'] == 0][col].mean()\n",
    "    print(f\"\\n{col.replace('_', ' ').title()}:\")\n",
    "    print(f\"  Purchase: {purchase_mean:.2f}\")\n",
    "    print(f\"  No Purchase: {no_purchase_mean:.2f}\")\n",
    "    print(f\"  Difference: {purchase_mean - no_purchase_mean:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purchase Behavior Insights:\n",
    "\n",
    "**Numerical Features Comparison:**\n",
    "- **Time Spent**: Purchasers spend more time (34.5 min vs 33.2 min, small difference)\n",
    "- **Pages Viewed**: Purchasers view more pages (10.1 vs 7.9, moderate difference)\n",
    "- **Basket Value**: Purchasers have higher basket values ($52.1 vs $33.5, large difference)\n",
    "\n",
    "**Categorical Features:**\n",
    "- **Device Type**: Mobile users have highest purchase rate (~83%), Desktop lowest (~77%)\n",
    "- **Customer Type**: Returning customers purchase at higher rate (~85% vs ~76% for new)\n",
    "\n",
    "**Key Patterns:**\n",
    "- Basket value appears to be the strongest discriminator between purchasers and non-purchasers\n",
    "- Returning customers show higher purchase intent than new customers\n",
    "- Device type shows some variation but less pronounced differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Analysis\n",
    "\n",
    "Let's examine relationships between features and identify potential multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "# First, create a copy with filled missing values for correlation analysis\n",
    "df_corr = df.copy()\n",
    "\n",
    "# Fill missing values with median/mean for correlation analysis\n",
    "df_corr['time_spent'].fillna(df_corr['time_spent'].median(), inplace=True)\n",
    "df_corr['pages_viewed'].fillna(df_corr['pages_viewed'].mean(), inplace=True)\n",
    "df_corr['basket_value'].fillna(0, inplace=True)\n",
    "df_corr['device_type'].fillna('Unknown', inplace=True)\n",
    "df_corr['customer_type'].fillna('New', inplace=True)\n",
    "\n",
    "# Encode categorical variables for correlation\n",
    "df_corr['device_type_encoded'] = df_corr['device_type'].map({'Mobile': 0, 'Desktop': 1, 'Tablet': 2, 'Unknown': 3})\n",
    "df_corr['customer_type_encoded'] = df_corr['customer_type'].map({'New': 0, 'Returning': 1})\n",
    "\n",
    "# Select features for correlation\n",
    "corr_features = ['time_spent', 'pages_viewed', 'basket_value', 'device_type_encoded', 'customer_type_encoded', 'purchase']\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = df_corr[corr_features].corr()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Matrix', fontsize=16, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print correlation with target\n",
    "print(\"\\n=== CORRELATION WITH TARGET (Purchase) ===\")\n",
    "target_corr = corr_matrix['purchase'].drop('purchase').sort_values(ascending=False)\n",
    "for feature, corr in target_corr.items():\n",
    "    print(f\"{feature.replace('_', ' ').title()}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Analysis Insights:\n",
    "\n",
    "**Key Correlations with Purchase:**\n",
    "- **Basket Value**: 0.431 (Strongest positive correlation)\n",
    "- **Pages Viewed**: 0.266 (Moderate positive correlation)\n",
    "- **Time Spent**: 0.042 (Weak positive correlation)\n",
    "- **Customer Type**: 0.157 (Weak positive correlation)\n",
    "- **Device Type**: -0.063 (Weak negative correlation)\n",
    "\n",
    "**Multicollinearity Check:**\n",
    "- No strong correlations between predictor variables (all < 0.3)\n",
    "- Features appear relatively independent\n",
    "\n",
    "**Feature Importance Implications:**\n",
    "- Basket value emerges as the most predictive feature\n",
    "- Time spent shows surprisingly weak correlation despite being intuitive\n",
    "- Categorical features have modest predictive power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Analysis\n",
    "\n",
    "Let's check for potential outliers in our numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier analysis using box plots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "numerical_cols = ['time_spent', 'pages_viewed', 'basket_value']\n",
    "\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    # Create box plot\n",
    "    box_data = df[col].dropna()\n",
    "    bp = axes[i].boxplot(box_data, patch_artist=True, \n",
    "                        boxprops=dict(facecolor='lightblue', color='blue'),\n",
    "                        medianprops=dict(color='red', linewidth=2),\n",
    "                        whiskerprops=dict(color='blue'),\n",
    "                        capprops=dict(color='blue'),\n",
    "                        flierprops=dict(marker='o', markerfacecolor='red', markersize=8, alpha=0.6))\n",
    "    \n",
    "    axes[i].set_title(f'{col.replace(\"_\", \" \").title()} Distribution', fontweight='bold')\n",
    "    axes[i].set_ylabel(col.replace('_', ' ').title())\n",
    "    axes[i].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical outlier detection using IQR method\n",
    "print(\"=== OUTLIER ANALYSIS (IQR Method) ===\")\n",
    "for col in numerical_cols:\n",
    "    data = df[col].dropna()\n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q3 = data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = data[(data < lower_bound) | (data > upper_bound)]\n",
    "    \n",
    "    print(f\"\\n{col.replace('_', ' ').title()}:\")\n",
    "    print(f\"  IQR: {IQR:.2f}\")\n",
    "    print(f\"  Outlier Range: < {lower_bound:.2f} or > {upper_bound:.2f}\")\n",
    "    print(f\"  Outliers Found: {len(outliers)} ({len(outliers)/len(data)*100:.1f}%)\")\n",
    "    if len(outliers) > 0:\n",
    "        print(f\"  Outlier Values: {sorted(outliers.values)[:5]}...\")  # Show first 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Analysis Results:\n",
    "\n",
    "**Outlier Distribution:**\n",
    "- **Time Spent**: 6 outliers (1.4%) - Some extreme browsing sessions\n",
    "- **Pages Viewed**: 3 outliers (0.7%) - Users viewing many pages\n",
    "- **Basket Value**: 3 outliers (0.7%) - High-value shopping baskets\n",
    "\n",
    "**Assessment:**\n",
    "- Relatively few outliers in the dataset\n",
    "- Outliers appear legitimate (e.g., users spending long time shopping, high basket values)\n",
    "- No extreme outliers that would require removal\n",
    "- Data scaling will handle any remaining scale differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Key Findings\n",
    "\n",
    "### Dataset Characteristics\n",
    "- **Size**: 500 customer sessions\n",
    "- **Features**: 6 predictors + 1 binary target\n",
    "- **Missing Values**: Present in all features except customer_id and purchase\n",
    "- **Class Imbalance**: 81.4% purchase rate (407 yes, 93 no)\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "**Strongest Predictors:**\n",
    "1. **Basket Value** (correlation = 0.431) - Most predictive feature\n",
    "2. **Pages Viewed** (correlation = 0.266) - Moderate relationship\n",
    "3. **Customer Type** (correlation = 0.157) - Returning customers more likely to purchase\n",
    "\n",
    "**Data Quality:**\n",
    "- Missing values require imputation following business rules\n",
    "- No concerning multicollinearity between features\n",
    "- Outliers are minimal and appear legitimate\n",
    "\n",
    "**Business Implications:**\n",
    "- **Marketing Focus**: Target customers with high basket values\n",
    "- **User Experience**: Optimize for mobile users (45.8% of traffic)\n",
    "- **Retention**: Leverage returning customer behavior patterns\n",
    "\n",
    "### Next Steps for Modeling\n",
    "1. **Preprocessing**: Handle missing values, encode categoricals, scale features\n",
    "2. **Feature Engineering**: Consider interaction terms, behavioral segments\n",
    "3. **Class Imbalance**: Address 4.4:1 purchase:no-purchase ratio\n",
    "4. **Model Selection**: Focus on precision-recall balance for business value\n",
    "5. **Evaluation**: Use appropriate metrics for imbalanced classification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
